{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest-neighbor algorithm in plain Python\n",
    "\n",
    "The k-nn algorithm is a simple **supervised** machine learning algorithm that can be used both for classification and regression. It's an **instance-based** algorithm. So instead of estimating a model, it stores all training examples in memory and makes predictions using a similarity measure. \n",
    "\n",
    "But it requires a large amount of memory, which depends directly on the number of instances. And it needs to be compared with known instances when predicting, so the running time will be relatively longer.\n",
    "\n",
    "Given an input example, the k-nn algorithm retrieves the k most similar instances from memory. Similarity is defined in terms of distance, that is, the training examples with the smallest (Euclidean, Manhattan, ect.) distance to the input example are considered to be most similar.\n",
    "\n",
    "The target value of the input example is computed as follows:  \n",
    "  \n",
    "Classification:  \n",
    "a) unweighted: output the most common classification among the k-nearest neighbors  \n",
    "b) weighted: sum up the weights of the k-nearest neighbors for each classification value, output classification with highest weight  \n",
    "  \n",
    "Regression:  \n",
    "a) unweighted: output the average of the values of the k-nearest neighbors  \n",
    "b) weighted: for all classification values,  sum up classification value$*$weight and divide the result trough the sum of all weights  \n",
    "\n",
    "The weighted k-nn version is a refined version of the algorithm in which the contribution of each neighbor is *weighted* according to its distance to the query point. Below, we implement the basic unweighted version of the k-nn algorithm for the digits dataset from sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3.1 in Lihang's book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1,1], dtype = np.float32)\n",
    "x2 = np.array([5,1], dtype = np.float32)\n",
    "x3 = np.array([4,4], dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance between x and y, default is Euclidean distance\n",
    "def Dist(x, y, p = 2):\n",
    "    dist = np.linalg.norm(x - y, p)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1(x1, x2) = 4.0\n",
      "L2(x1, x2) = 4.0\n",
      "L3(x1, x2) = 4.0\n",
      "L4(x1, x2) = 4.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    dist_x1_x2 = Dist(x1, x2, p = i)\n",
    "    print('L{}(x1, x2) = {:.3}'.format(i, dist_x1_x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1(x1, x3) = 6.0\n",
      "L2(x1, x3) = 4.24\n",
      "L3(x1, x3) = 3.78\n",
      "L4(x1, x3) = 3.57\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    dist_x1_x3 = Dist(x1, x3, p =i)\n",
    "    print('L{}(x1, x3) = {:.3}'.format(i, dist_x1_x3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 3.1 illustrates that the vector $\\boldsymbol x_2$ or the vector $\\boldsymbol x_3$ is closest to the vector $\\boldsymbol x_1$ if $p <= 2$ or $p >= 3$ respectively.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sk = KNeighborsClassifier(n_neighbors=3)\n",
    "clf_sk.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sk.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf_sk.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
